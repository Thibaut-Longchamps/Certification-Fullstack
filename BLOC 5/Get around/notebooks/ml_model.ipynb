{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\33760\\anaconda3\\envs\\myenv\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "import os \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_key</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine_power</th>\n",
       "      <th>fuel</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>car_type</th>\n",
       "      <th>private_parking_available</th>\n",
       "      <th>has_gps</th>\n",
       "      <th>has_air_conditioning</th>\n",
       "      <th>automatic_car</th>\n",
       "      <th>has_getaround_connect</th>\n",
       "      <th>has_speed_regulator</th>\n",
       "      <th>winter_tires</th>\n",
       "      <th>rental_price_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Citroën</td>\n",
       "      <td>140411</td>\n",
       "      <td>100</td>\n",
       "      <td>diesel</td>\n",
       "      <td>black</td>\n",
       "      <td>convertible</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Citroën</td>\n",
       "      <td>183297</td>\n",
       "      <td>120</td>\n",
       "      <td>diesel</td>\n",
       "      <td>white</td>\n",
       "      <td>convertible</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Citroën</td>\n",
       "      <td>128035</td>\n",
       "      <td>135</td>\n",
       "      <td>diesel</td>\n",
       "      <td>red</td>\n",
       "      <td>convertible</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Citroën</td>\n",
       "      <td>97097</td>\n",
       "      <td>160</td>\n",
       "      <td>diesel</td>\n",
       "      <td>silver</td>\n",
       "      <td>convertible</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Citroën</td>\n",
       "      <td>152352</td>\n",
       "      <td>225</td>\n",
       "      <td>petrol</td>\n",
       "      <td>black</td>\n",
       "      <td>convertible</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_key  mileage  engine_power    fuel paint_color     car_type  \\\n",
       "0   Citroën   140411           100  diesel       black  convertible   \n",
       "1   Citroën   183297           120  diesel       white  convertible   \n",
       "2   Citroën   128035           135  diesel         red  convertible   \n",
       "3   Citroën    97097           160  diesel      silver  convertible   \n",
       "4   Citroën   152352           225  petrol       black  convertible   \n",
       "\n",
       "   private_parking_available  has_gps  has_air_conditioning  automatic_car  \\\n",
       "0                       True     True                 False          False   \n",
       "1                      False    False                 False          False   \n",
       "2                       True     True                 False          False   \n",
       "3                       True     True                 False          False   \n",
       "4                       True     True                 False          False   \n",
       "\n",
       "   has_getaround_connect  has_speed_regulator  winter_tires  \\\n",
       "0                   True                 True          True   \n",
       "1                   True                False          True   \n",
       "2                   True                 True          True   \n",
       "3                  False                 True          True   \n",
       "4                   True                 True          True   \n",
       "\n",
       "   rental_price_per_day  \n",
       "0                   106  \n",
       "1                   101  \n",
       "2                   158  \n",
       "3                   183  \n",
       "4                   131  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\33760\\Desktop\\FULLSTACK\\FULLSTACK\\Projet\\BLOC 5\\Get around\\api\\data\\clean_pricing_project.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mileage', 'engine_power', 'fuel', 'paint_color', 'car_type',\n",
       "       'private_parking_available', 'has_gps', 'has_air_conditioning',\n",
       "       'automatic_car', 'has_getaround_connect', 'has_speed_regulator',\n",
       "       'winter_tires', 'rental_price_per_day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete 'model_key_column' (high cardinality)\n",
    "df = df.iloc[:,1:]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating labels from features...\n",
      "...Done.\n",
      "\n",
      "Y : \n",
      "0    106\n",
      "1    101\n",
      "2    158\n",
      "3    183\n",
      "4    131\n",
      "Name: rental_price_per_day, dtype: int64\n",
      "\n",
      "X :\n",
      "   mileage  engine_power    fuel paint_color     car_type  \\\n",
      "0   140411           100  diesel       black  convertible   \n",
      "1   183297           120  diesel       white  convertible   \n",
      "2   128035           135  diesel         red  convertible   \n",
      "3    97097           160  diesel      silver  convertible   \n",
      "4   152352           225  petrol       black  convertible   \n",
      "\n",
      "   private_parking_available  has_gps  has_air_conditioning  automatic_car  \\\n",
      "0                       True     True                 False          False   \n",
      "1                      False    False                 False          False   \n",
      "2                       True     True                 False          False   \n",
      "3                       True     True                 False          False   \n",
      "4                       True     True                 False          False   \n",
      "\n",
      "   has_getaround_connect  has_speed_regulator  winter_tires  \n",
      "0                   True                 True          True  \n",
      "1                   True                False          True  \n",
      "2                   True                 True          True  \n",
      "3                  False                 True          True  \n",
      "4                   True                 True          True  \n"
     ]
    }
   ],
   "source": [
    "# Separate target variable Y from features X\n",
    "print(\"Separating labels from features...\")\n",
    "\n",
    "features_list = [\n",
    "    \"mileage\",\n",
    "    \"engine_power\",\n",
    "    \"fuel\",\n",
    "    \"paint_color\", \n",
    "    \"car_type\",\n",
    "    \"private_parking_available\", \n",
    "    \"has_gps\",\n",
    "    \"has_air_conditioning\", \n",
    "    \"automatic_car\",\n",
    "    \"has_getaround_connect\", \n",
    "    \"has_speed_regulator\",\n",
    "    \"winter_tires\"\n",
    "    ]\n",
    "\n",
    "target_variable = \"rental_price_per_day\"\n",
    "\n",
    "X = df.loc[:,features_list]\n",
    "Y = df.loc[:,target_variable]\n",
    "\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "print('Y : ')\n",
    "print(Y.head())\n",
    "print()\n",
    "print('X :')\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found numeric features  ['mileage', 'engine_power']\n",
      "\n",
      "Found categorical features  ['fuel', 'paint_color', 'car_type', 'private_parking_available', 'has_gps', 'has_air_conditioning', 'automatic_car', 'has_getaround_connect', 'has_speed_regulator', 'winter_tires']\n"
     ]
    }
   ],
   "source": [
    "# Automatically detect names of numeric/categorical columns\n",
    "numeric_features = []\n",
    "categorical_features = []\n",
    "for i,t in X.dtypes.iteritems():\n",
    "    if ('float' in str(t)) or ('int' in str(t)) :\n",
    "        numeric_features.append(i)\n",
    "    else :\n",
    "        categorical_features.append(i)\n",
    "\n",
    "print('\\nFound numeric features ', numeric_features)\n",
    "print('\\nFound categorical features ', categorical_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for numeric features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create pipeline for categorical features\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('encoder', OneHotEncoder(drop='first')) # first column will be dropped to avoid creating correlations between features\n",
    "    ])\n",
    "\n",
    "# Use ColumnTransformer to make a preprocessor object that describes all the treatments to be done\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate data (X_TRAIN / Y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing X_train...\n",
      "\n",
      "...Done!\n",
      "  (0, 0)\t0.6775767536894776\n",
      "  (0, 1)\t0.9644456050336777\n",
      "  (0, 5)\t1.0\n",
      "  (0, 15)\t1.0\n",
      "  (0, 21)\t1.0\n",
      "  (0, 22)\t1.0\n",
      "  (0, 23)\t1.0\n",
      "  (0, 27)\t1.0\n",
      "  (1, 0)\t0.6202090944865828\n",
      "  (1, 1)\t-0.7584179358043706\n",
      "  (1, 5)\t1.0\n",
      "  (1, 16)\t1.0\n",
      "  (1, 22)\t1.0\n",
      "  (1, 25)\t1.0\n",
      "  (1, 27)\t1.0\n",
      "  (2, 0)\t-0.725511557799086\n",
      "  (2, 1)\t-0.6148459740678665\n",
      "  (2, 13)\t1.0\n",
      "  (2, 19)\t1.0\n",
      "  (2, 22)\t1.0\n",
      "  (2, 24)\t1.0\n",
      "  (2, 26)\t1.0\n",
      "  (2, 27)\t1.0\n",
      "  (3, 0)\t0.4499389494402912\n",
      "  (3, 1)\t-0.47127401233136246\n",
      "  (3, 13)\t1.0\n",
      "  (3, 19)\t1.0\n",
      "  (3, 21)\t1.0\n",
      "  (3, 22)\t1.0\n",
      "  (3, 25)\t1.0\n",
      "  (3, 27)\t1.0\n",
      "  (4, 0)\t-0.5234967527721511\n",
      "  (4, 1)\t-0.7584179358043706\n",
      "  (4, 9)\t1.0\n",
      "  (4, 19)\t1.0\n",
      "  (4, 21)\t1.0\n",
      "  (4, 22)\t1.0\n",
      "  (4, 25)\t1.0\n",
      "  (4, 26)\t1.0\n",
      "  (4, 27)\t1.0\n",
      "\n",
      "Preprocessing X_test...\n",
      "\n",
      "...Done!\n",
      "  (0, 0)\t1.3261062275665474\n",
      "  (0, 1)\t1.5387334519796938\n",
      "  (0, 13)\t1.0\n",
      "  (0, 17)\t1.0\n",
      "  (0, 21)\t1.0\n",
      "  (0, 22)\t1.0\n",
      "  (0, 25)\t1.0\n",
      "  (0, 27)\t1.0\n",
      "  (1, 0)\t0.13082447200208006\n",
      "  (1, 1)\t-0.7584179358043706\n",
      "  (1, 5)\t1.0\n",
      "  (1, 17)\t1.0\n",
      "  (1, 22)\t1.0\n",
      "  (1, 26)\t1.0\n",
      "  (1, 27)\t1.0\n",
      "  (2, 0)\t0.0016281046790112877\n",
      "  (2, 1)\t-0.6148459740678665\n",
      "  (2, 5)\t1.0\n",
      "  (2, 19)\t1.0\n",
      "  (3, 0)\t0.7972790483393516\n",
      "  (3, 1)\t-0.7584179358043706\n",
      "  (3, 6)\t1.0\n",
      "  (3, 15)\t1.0\n",
      "  (3, 22)\t1.0\n",
      "  (3, 27)\t1.0\n",
      "  (4, 0)\t0.1707802218622432\n",
      "  (4, 1)\t0.2465857963511576\n",
      "  (4, 13)\t1.0\n",
      "  (4, 15)\t1.0\n",
      "  (4, 22)\t1.0\n",
      "  (4, 23)\t1.0\n",
      "  (4, 27)\t1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=0)\n",
    "\n",
    "print(\"Preprocessing X_train...\")\n",
    "print()\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "print(\"...Done!\")\n",
    "print(X_train[0:5,:]) # X_train is now a numpy array\n",
    "print()\n",
    "\n",
    "# Test pipeline\n",
    "print(\"Preprocessing X_test...\")\n",
    "print()\n",
    "X_test = preprocessor.transform(X_test) # Don't fit again !! The test set is used for validating decisions\n",
    "# we made based on the training set, therefore we can only apply transformations that were parametered using the training set.\n",
    "# Otherwise this creates what is called a leak from the test set which will introduce a bias in all your results.\n",
    "print(\"...Done!\")\n",
    "print(X_test[0:5,:]) # X_test is now a numpy array\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No free lunch theorem method for optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model...\n",
      "...Done.\n",
      "Predictions on training set...\n",
      "...Done.\n",
      "[120.48294151 106.05062487 135.1621775  ...  98.95759523 141.38200537\n",
      "  91.88165016]\n",
      "\n",
      "Predictions on test set...\n",
      "...Done.\n",
      "[135.19605787 111.13323369 103.81900296  89.56512138 117.79891321\n",
      "  99.15317263  80.41344838 103.66891913 125.67815836 132.73253934\n",
      "  89.82393273 178.08345604 159.0340164  109.95922679 164.64546625\n",
      " 133.62656205 105.60570317 128.82308263 111.62216248  89.28432737\n",
      " 106.75470739 155.77016642 138.35711181 129.32841621 143.46363327\n",
      "  97.33850071  95.86271908 116.58003159 128.24799205 156.57171883\n",
      " 102.83865313 108.91753752 136.65260458 131.18256888  88.7863179\n",
      " 122.39345868 104.98810984 123.46811521 123.14961899 156.95407722\n",
      " 134.59762412 130.17380022 135.30919064 149.92964533 118.47618676\n",
      "  78.48322629 126.32855242 128.85047501 123.22461965 123.78760494\n",
      " 128.22328184 130.29673161 103.74956327 129.81511965 104.45139885\n",
      " 132.55263865  87.53638341 119.70928242 106.00683945 145.55586193\n",
      " 111.64649855  92.32624332 115.83672728 160.64921526  85.4038609\n",
      " 137.11405074  96.52994968 120.29809121 179.34262498 107.45949418\n",
      " 135.4670482  133.45715311 121.63910307 146.46377349 107.38521287\n",
      " 102.46027751 112.74795113 134.2871546  118.37291357 103.65611534\n",
      "  98.48418234 107.58474016 106.40121428  81.75092065 146.89204774\n",
      " 111.12093847 167.43111574 155.22053995 106.42806288 119.8372063\n",
      "  93.17632042 122.19250355 156.43259298 110.36788634  99.25022308\n",
      "  91.98555679 146.65110271 128.25131095 116.58453347 111.55917378\n",
      " 133.09295427 144.48183317 123.12027495 140.21009461 171.40703238\n",
      "  93.34682877 124.89605388 111.92928196 130.56826246 123.89320227\n",
      " 171.32293937 146.62017866 134.11593974 114.40452706 122.66559154\n",
      " 109.4315063  110.83467332 122.69571154 173.29150772 102.33834568\n",
      " 131.30796869  98.87415007 102.38111934  79.01272614 139.43091762\n",
      " 147.52726138 121.8281431  132.78565204 103.18099396 102.5417169\n",
      "  95.02784464 114.60343746 124.35713721 177.31903182 135.48126196\n",
      "  84.46592009  40.86265903  81.43719959 141.86990366 162.92507039\n",
      " 140.6073976  150.70676308  97.97222951 139.93925626 114.56729639\n",
      "  87.48954008 130.13843936 132.05966829  86.74779688 140.10619\n",
      " 137.60988262 108.33918602 113.70856678 142.1790886  134.25868076\n",
      " 150.54751878 142.82911791 101.98090578 199.00303072  93.3313398\n",
      " 143.04992028 140.27565203 115.66107032  84.56340766 144.86188694\n",
      " 100.3470825   84.68488628 121.18186368 148.16396906 136.34550995\n",
      " 120.35715384 149.17109531 131.96672435 113.54348768 108.77717858\n",
      " 146.8113785  125.02879039 122.83719773 155.4902018  109.05110278\n",
      " 106.91892185 114.81528787  77.56717949 134.32387348 109.68685295\n",
      " 135.52550177 107.04496691  67.43470598 118.69315483 111.91646139\n",
      " 104.48652523 145.82802441 107.0121143   72.84345858 102.79985822\n",
      " 123.0452962  136.66395667 183.29280927  75.4129139  118.06669997\n",
      " 159.89178234 108.82287907  95.58504366  91.23160103 122.00028672\n",
      " 107.74612635 116.723418   125.28113214 124.78177984 109.32011848\n",
      " 123.24786698 177.48775271 126.48795242  92.55115383 164.18558502\n",
      " 117.95439436 162.55916668 136.36318806 120.55005877 113.37692578\n",
      " 157.86462384 155.8837851  141.04519815 107.73858819 147.01578148\n",
      " 130.54580005 129.89336147 117.58931962 100.00671657 147.50485294\n",
      " 146.58685753 128.00662723 133.11710493 158.89328163 116.40333673\n",
      " 116.90127497 106.58748152 132.63266448 133.32938288 139.8572146\n",
      " 134.81023879 141.03071635 110.16574183  66.30128664 118.98942846\n",
      " 103.00444654 132.06840735 119.43572627 101.75222863  95.59977054\n",
      " 122.11929301 117.33896204 116.72639594  86.84463305 111.39037911\n",
      " 124.91973641  90.29279842 136.06064205 171.2211563   95.48673975\n",
      " 117.28625705 126.78799206 134.0031996  132.39377457  94.23886206\n",
      " 104.24988737 154.40457818 114.53958642 122.05311271 114.78141616\n",
      "  55.09842109 133.12055045 132.83648163 107.01135157 165.23778476\n",
      " 105.35142335 130.93826829 103.65646815 110.57010085 115.12814839\n",
      " 132.05330828  82.06424954 135.4029139  126.09171918  90.02998894\n",
      " 153.96400217 103.21137138 142.08137368 119.47805562 128.53228711\n",
      " 104.83172013 117.27016541 163.41169794 143.66200247 174.85520329\n",
      " 112.72518221 120.24641018 108.91549864 106.91152273 135.36923764\n",
      " 143.15009756 128.45937533 135.36873316 123.88096658  77.84962326\n",
      " 117.4995469   85.16978084 107.1626466  146.01887616  95.29421571\n",
      " 109.368544    84.6464452  106.01217724 118.08362648  89.6613449\n",
      "  95.7103996  153.09581894 135.4686923   82.09391401 111.12160725\n",
      "  64.62087971 108.38082036 130.93595838  73.36513826 169.31592972\n",
      " 116.84255612 106.99882552 140.94993644 118.18862346 140.02901684\n",
      " 150.04733197  73.04422309 122.41478508 109.79923444 125.1229554\n",
      "  96.50511615 111.35560516 113.16546404 120.28567423 175.76415525\n",
      " 105.48242275  80.31731506 117.21487065  93.85142856  91.49170817\n",
      " 163.46901961  83.98281169 131.82584008 156.61499873 102.23765291\n",
      "  98.12955227 142.23239167 104.49244491  91.14226905  45.41696795\n",
      " 134.51106269  79.83003877 140.19005678 140.99367725  74.97778622\n",
      " 118.30476648 108.09726791 122.76193411 112.66726459 120.18446699\n",
      " 113.51849716 105.93722621 168.16957873 110.7247168  112.07331567\n",
      "  97.41937941 148.38758509 113.69605939 138.57041334  98.37440312\n",
      "  88.19337244 123.28841793  88.19158949 134.81385417 133.62714284\n",
      "  92.80038574 106.66989813 123.12519263 113.52830894 111.41047303\n",
      " 144.19590272 160.77550649 101.03744098 137.38041569 107.50213765\n",
      " 143.32085126 106.58347822 103.32831115 175.34704811 130.50151683\n",
      "  92.1957263  131.4567699   94.91273468 148.63142232 124.72089038\n",
      " 158.47971497 132.26640343  99.68504456  94.11267984  92.93518837\n",
      "  91.46209904 109.20966418 125.77456878 156.54316065 142.15531538\n",
      "  91.13539125 135.81660606 105.49470447 138.4674538  115.44000896\n",
      "  98.97616085 134.49007444 130.19670958 145.77246894 194.64348934\n",
      " 155.63520424 118.46264125 105.59067972  99.70222196 159.162605\n",
      "  90.22727801 130.56158418  69.92446649 134.97347781 104.40180826\n",
      " 120.52064051 123.51818316 111.24302521 127.32627945  90.37357432\n",
      " 128.69739774 122.86507093 109.03334925 157.98652993 154.16772827\n",
      " 129.49986593 115.32258654 151.16574376  98.82561128 135.47847748\n",
      " 120.91815733  88.27012603  68.2825636  176.29721156 180.61261259\n",
      " 123.48005071 148.87818576 162.72265154  95.70297077 134.41760288\n",
      " 105.78125999  81.07824043 130.12669008  92.13266278  99.78012032\n",
      " 119.72702542 130.33031454 140.22887684 126.76239872 138.55989282\n",
      " 100.35664855 111.25627802 111.38234949 122.67856962 126.31047889\n",
      " 125.24858172 157.47672714  96.85980728  95.81122477 117.75660758\n",
      " 132.33354134 121.60141651 133.20707968 173.0719845  130.70798405\n",
      " 119.70134413 105.07743966 114.99437716  83.55650033 150.14939704\n",
      " 129.73567538 143.19372526 167.6302732  152.84798014 133.64887851\n",
      " 130.93422233 115.77961521  97.83643595  80.63566904 125.61560575\n",
      " 128.3340632  134.99651735 105.46646378 118.77184855 130.02050544\n",
      " 126.72162941 110.44479334  94.91480854 103.64417111 103.25632255\n",
      " 122.54170064 136.27363894 121.68319772 113.96748064  89.61817609\n",
      " 114.13985765 139.96277709  99.34054011 103.96928897 148.67661321\n",
      " 123.22061694 108.34700907 108.35764103 116.05632065 126.01835722\n",
      " 138.34801292 148.7819736  117.7410388  119.2274028  119.57574004\n",
      " 160.45069641 116.46776452  94.21472983 139.03756317 137.19021046\n",
      " 105.30164194 149.28242971 102.21926534 194.77811007 175.90391719\n",
      " 139.09938963 122.69812416 180.78722278 123.03148843 127.00904332\n",
      " 177.00159513 167.53703647 133.29443576 157.16542256 115.26215164\n",
      " 101.87513427 177.7126808   99.01124541 125.32744761 114.55301343\n",
      " 180.95297951  97.78380349  80.56465071 129.72501069 102.90346682\n",
      " 111.70116288 123.29562486 136.60869392 105.60185674 156.08504683\n",
      " 159.25480917 103.46774971 116.09667056 173.22114761 155.69811143\n",
      " 112.00038044 112.63574928 124.52700539 152.76039785 137.3222381\n",
      " 133.94932049 121.43780365 138.41251132 129.64029383 138.59027613\n",
      " 116.33141139 140.4924285  128.90101013  57.81612603 168.08623365\n",
      " 113.84137605  98.59897263 133.54381442 148.55661083 117.09524859\n",
      " 108.18436747 116.76382356  82.03948935 116.8181066   73.71046536\n",
      " 118.045629   141.24343602 116.13682763 116.58665405 101.42849393\n",
      " 157.5702978  119.12144345 111.44109957 118.09578428 161.00497232\n",
      " 152.10276955  96.47749281 137.16233676 103.28256743 135.8131423\n",
      " 165.21061944 122.09060568  92.27435353 132.1479779  164.85665576\n",
      " 148.55557232  95.09218767 161.02385897 135.44523673 131.46815679\n",
      " 148.9500885  176.11278085 124.85941458 107.50614091 138.91610389\n",
      "  99.04426469 120.46571146  67.10874163 141.36174228 101.00767366\n",
      " 159.71204257 152.20353604  74.43677423  99.1348208   86.20867657\n",
      " 123.8213587  122.28679878 121.29633854 117.03881561 171.7416683\n",
      " 102.87911668 111.511502   111.26072507 116.84131537  90.5839822\n",
      " 128.8823865  159.35177608 103.74273735 144.88850776 127.77918939\n",
      " 128.67569991 117.6276133  107.59913897 103.67634171 118.53977099\n",
      "  63.87669663 111.41279275 110.5143198  132.65033928 120.04488093\n",
      "  99.28802511 100.67110735 115.65142441 101.00297915  96.19644867\n",
      " 147.20220283 133.112609   102.24655458 105.56557362 147.94107494\n",
      " 109.9168648  111.03938815 122.83684524 106.9716382  151.63480399\n",
      " 125.56878918 108.08576472 154.66294079 153.84567075 152.1219227\n",
      " 114.1739943  166.2794509  158.50532753 102.06173028 140.01008193\n",
      " 118.84290049  78.25332063  96.83703702 152.73960052 131.02058468\n",
      " 104.2748869  116.58932565  85.78759703 116.14051711 173.21293242\n",
      " 147.79595129 133.09497831 124.47059213 128.70900676 100.91744068\n",
      " 110.16321899 112.6603103  113.34266404 100.97385756 107.9505149\n",
      " 135.06528918 173.47162049 158.72118456 101.45241698 128.27987182\n",
      "  83.87696666 104.56886418 101.8194034  128.20609877 128.55575342\n",
      " 122.10147261 196.10406887 124.18694627 135.21117732 152.66495212\n",
      " 121.07421236 106.06343985 129.46317169 131.31482444 136.82106819\n",
      " 102.73841902 125.52333213 115.83270673 136.31325119 105.65949914\n",
      "  99.87957114 142.11242574 101.58580665 129.31311352 115.99750784\n",
      " 111.51636315 107.97613723 102.48223101 106.30808926 158.88874456\n",
      " 127.3370806  146.54788788 156.18102013 131.31457154 124.79800663\n",
      " 129.23191762  87.20432314 133.43317459  90.56867463  89.42001388\n",
      " 130.59959202  94.57717116  96.57521266  73.54449002 145.61165511\n",
      " 174.69072473 104.43686113  96.527023    87.31275757  99.3804433\n",
      " 116.5998608  131.6227067  139.8103512  119.36875956 135.35031221\n",
      "  86.29387626 133.04526382 122.64107999 125.87526713 163.31271494\n",
      " 139.96378148 107.60213441  77.86351312 115.8133545   95.15418592\n",
      " 127.19814084 126.56492277 156.92332925 129.23457215  61.67917725\n",
      " 140.78328961 139.90982471 107.72200913 119.22381357 144.69267365\n",
      "  89.61524778 111.46701367 150.88884254 113.31831478 137.40103917\n",
      " 113.17020438  98.95788875 119.50818185  95.92321431 113.10001305\n",
      "  85.61172473 137.33761541 122.38327567 118.30556957  80.11836237\n",
      " 151.54850236 126.77215683 125.84467686 143.69638788 112.7339735\n",
      "  71.46888889  96.13205602 138.76053464 168.52792099 108.09320862\n",
      " 111.07923056 109.55317306 119.22443557  60.2622193  104.87220568\n",
      " 184.94504305 116.55620921 110.67177359  96.9248326  110.75124051\n",
      " 100.83753501 112.28837905 116.05239558 133.37066804 122.6036069\n",
      " 119.62614675 190.82467989 118.7048403  108.19401625 131.39689319\n",
      "  74.9508229  179.52838516 120.33398164 169.14855695 105.69712108\n",
      " 118.00033998  82.65997313 129.07767731 168.32617647 122.63907473\n",
      "  93.14998486 134.88681705 103.57909724 107.86839649 117.48660011\n",
      " 111.24397789 115.78398138 132.56182886 101.25106535 127.18937204\n",
      " 123.46665738  84.79356092 180.41583539 107.88567024 180.79770009\n",
      " 107.83297173 121.15069615 130.09393065 141.26466892 129.05950494\n",
      " 152.36690821 105.40384556 104.62481856  91.38289953 182.54154313\n",
      " 152.80471796 130.2136066  116.38756273  97.60636533 114.7423347\n",
      " 102.09638152 115.62674624 159.32607943 111.394464    90.11694177\n",
      " 103.845256   113.80045052 118.19070402 150.70388437 103.69397902\n",
      " 157.97925527 167.31883728  79.43110379 157.12686534  83.44208797\n",
      " 101.02475074 148.98201269 148.17940311 115.10335419  86.6291525\n",
      "  86.00335265 100.73079798 108.55541847 104.57404816 102.41008171\n",
      " 164.49044443 106.4614349  114.20183369 112.50745048 103.67031315\n",
      " 132.98725218 172.45400192 112.21044229 103.59569566  99.51514866\n",
      "  96.09320767  89.44764933  91.53978022 130.78015408  87.28164133\n",
      " 181.93721903 142.38950047 121.25067819 122.16722125 120.63265702\n",
      " 106.42940967 107.91282623 101.33018555  98.69814788 128.59708406\n",
      " 130.84024588 157.665563    99.15969472 126.91259383  93.77445647\n",
      " 131.61359364 133.42621093 125.68376063 112.02472218 112.42406414\n",
      "  98.7622183  101.12626379 112.09053205 103.22728289 167.02522997\n",
      "  99.25566227 109.52014611 127.19073577 154.02356924 164.4158874\n",
      " 117.43995966 116.62296157  73.98377006  91.46539558 108.81558904\n",
      " 139.07159449 118.10265973 106.74441454]\n",
      "\n",
      "R2 score on training set :  0.6560023612677449\n",
      "R2 score on test set :  0.6952776717702762\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Train model...\")\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = linreg.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred)\n",
    "print()\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = linreg.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred)\n",
    "print()\n",
    "\n",
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", r2_score(Y_train, Y_train_pred))\n",
    "print(\"R2 score on test set : \", r2_score(Y_test, Y_test_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The R2 score on the training set is 0.656, which means that the model explains approximately 65.6% of the observed variance in the training data. In other words, it reasonably captures the relationship between the independent variables and the target variable in the training dataset.\n",
    "\n",
    "The R2 score on the test set is 0.695, indicating that our model generalizes its predictions to new data with an accuracy of 69.5%. This means that it explains approximately 69.5% of the variance in the test data. The score on the test set is slightly higher than the score on the training set, suggesting that your model is not overly overfit and is capable of generalizing its predictions to new data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go further with a Lasso regularization (feature selection model) and griedsearch !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Done.\n",
      "Best hyperparameters :  {'alpha': 0.018}\n",
      "R2 score on training set :  0.6550840393170925\n",
      "R2 score on test set :  0.6906686689100536\n",
      "Best validation R2 :  0.6474408210765583\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "lasso = Lasso(random_state=0)\n",
    "\n",
    "# Grid of values to be tested\n",
    "params = {\n",
    "    'alpha': [0.01, 0.018, 0.02]\n",
    "}\n",
    "\n",
    "gridsearch_lasso = GridSearchCV(lasso, param_grid = params, cv = 4) # cv : the number of folds to be used for CV\n",
    "gridsearch_lasso.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", gridsearch_lasso.best_params_)\n",
    "\n",
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", gridsearch_lasso.score(X_train, Y_train))\n",
    "print(\"R2 score on test set : \", gridsearch_lasso.score(X_test, Y_test))\n",
    "print(\"Best validation R2 : \", gridsearch_lasso.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the regularisation of Lasso and the griedsearch, we have not seen any real improvement in the model's performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG BOOST regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Done.\n",
      "Best hyperparameters :  {'colsample_bytree': 0.5, 'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 150, 'subsample': 0.8}\n",
      "R2 XGBoost default train 0.9185012881989117\n",
      "R2 XGBoost default test 0.7707262786265997\n",
      "Best validation R2 :  0.7231961731388532\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "print(\"Grid search...\")\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Grid of values to be tested\n",
    "\n",
    "params = {\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [150],\n",
    "    'colsample_bytree': [0.3, 0.5, 0.6],\n",
    "    'subsample': [0.5, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "xgb_gridsearch = GridSearchCV(xgb, param_grid = params, cv = 4) # cv : the number of folds to be used for CV\n",
    "xgb_gridsearch.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", xgb_gridsearch.best_params_)\n",
    "\n",
    "print(\"R2 XGBoost default train {}\".format(xgb_gridsearch.score(X_train, Y_train)))\n",
    "print(\"R2 XGBoost default test {}\".format(xgb_gridsearch.score(X_test, Y_test)))\n",
    "print(\"Best validation R2 : \", xgb_gridsearch.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Tree max depth 3 train 0.49788605226304095\n",
      "R2 Tree max depth 3 test 0.5289806676175105\n"
     ]
    }
   ],
   "source": [
    "tree_regressor = DecisionTreeRegressor(max_depth=3)\n",
    "tree_regressor.fit(X_train, Y_train)\n",
    "\n",
    "print(\"R2 Tree max depth 3 train {}\".format(tree_regressor.score(X_train, Y_train)))\n",
    "print(\"R2 Tree max depth 3 test {}\".format(tree_regressor.score(X_test, Y_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree regressor Griedsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search...\n",
      "...Done.\n",
      "Best hyperparameters :  {'max_depth': 10, 'min_samples_leaf': 12, 'min_samples_split': 4}\n",
      "\n",
      "R2 on training set :  0.7321175728116128\n",
      "R2 on test set :  0.6659107182117999\n",
      "Best validation R2 :  0.608875587201032\n"
     ]
    }
   ],
   "source": [
    "# Decision tree\n",
    "# Perform grid search\n",
    "print(\"Grid search...\")\n",
    "dtg = DecisionTreeRegressor()\n",
    "\n",
    "# Grid of values to be tested\n",
    "params = {\n",
    "    'max_depth': [7, 10, 15], \n",
    "    'min_samples_leaf': [10, 12, 14],\n",
    "    'min_samples_split': [3, 4, 5]\n",
    "}\n",
    "dt_opt = GridSearchCV(dtg, param_grid = params, cv = 3) # cv : the number of folds to be used for CV\n",
    "dt_opt.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", dt_opt.best_params_)\n",
    "print()\n",
    "print(\"R2 on training set : \", dt_opt.score(X_train, Y_train))\n",
    "print(\"R2 on test set : \", dt_opt.score(X_test, Y_test))\n",
    "print(\"Best validation R2 : \", dt_opt.best_score_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with default hyperparameters...\n",
      "...Done.\n",
      "\n",
      "R2 score on training set :  0.9583129336772048\n",
      "R2 score on test set :  0.7423322484008744\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "print(\"Random Forest with default hyperparameters...\")\n",
    "rf = RandomForestRegressor() # we must use a regressor here!\n",
    "rf.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", rf.score(X_train, Y_train))\n",
    "print(\"R2 score on test set : \", rf.score(X_test, Y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest regressor gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search...\n",
      "...Done.\n",
      "Best hyperparameters :  {'max_depth': 35, 'min_samples_split': 6, 'n_estimators': 250}\n",
      "\n",
      "R2 score on training set :  0.9177594705922483\n",
      "R2 score on test set :  0.7438267506301783\n",
      "Best validation R2 :  0.7048688789852193\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "print(\"Grid search...\")\n",
    "rfg = RandomForestRegressor()\n",
    "\n",
    "# Grid of values to be tested\n",
    "params = {\n",
    "    'max_depth': [30, 35, 40],\n",
    "    'min_samples_split': [4, 6, 8],\n",
    "    'n_estimators': [250]\n",
    "}\n",
    "rfg_gridsearch = GridSearchCV(rfg, param_grid = params, cv = 5)\n",
    "rfg_gridsearch.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", rfg_gridsearch.best_params_)\n",
    "print()\n",
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", rfg_gridsearch.score(X_train, Y_train))\n",
    "print(\"R2 score on test set : \", rfg_gridsearch.score(X_test, Y_test))\n",
    "print(\"Best validation R2 : \", rfg_gridsearch.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search...\n",
      "{'n_estimators': [50, 60, 70, 80, 90, 100], 'learning_rate': [0.01, 0.05, 1.0, 1.5, 2]}\n",
      "...Done.\n",
      "Best hyperparameters :  {'learning_rate': 0.05, 'n_estimators': 90}\n",
      "\n",
      "R2 on training set :  0.5837760596969497\n",
      "R2 on test set :  0.5994624203040251\n",
      "Best validation R2 :  0.5612378769523838\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "print(\"Grid search...\")\n",
    "adaboost = AdaBoostRegressor()\n",
    "\n",
    "# Grid of values to be tested\n",
    "params = {\n",
    "    'n_estimators':[80, 90, 100],\n",
    "    \"learning_rate\":[0.01, 0.05, 1.0]\n",
    "}\n",
    "print(params)\n",
    "ada_gridsearch = GridSearchCV(adaboost, param_grid = params, cv = 5) # cv : the number of folds to be used for CV\n",
    "ada_gridsearch.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", ada_gridsearch.best_params_)\n",
    "\n",
    "print()\n",
    "print(\"R2 on training set : \", ada_gridsearch.score(X_train, Y_train))\n",
    "print(\"R2 on test set : \", ada_gridsearch.score(X_test, Y_test))\n",
    "print(\"Best validation R2 : \", ada_gridsearch.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train R2</th>\n",
       "      <th>Test R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgb_regressor</td>\n",
       "      <td>0.918501</td>\n",
       "      <td>0.770726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>random_forest_g</td>\n",
       "      <td>0.884417</td>\n",
       "      <td>0.744979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random_forest_r</td>\n",
       "      <td>0.958936</td>\n",
       "      <td>0.741947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear_regression</td>\n",
       "      <td>0.656002</td>\n",
       "      <td>0.695278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lasso</td>\n",
       "      <td>0.655084</td>\n",
       "      <td>0.690669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decision_tree_g</td>\n",
       "      <td>0.676867</td>\n",
       "      <td>0.664391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adaboost_regressor_g</td>\n",
       "      <td>0.576523</td>\n",
       "      <td>0.592496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decision_tree_r</td>\n",
       "      <td>0.497886</td>\n",
       "      <td>0.528981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Train R2   Test R2\n",
       "2         xgb_regressor  0.918501  0.770726\n",
       "6       random_forest_g  0.884417  0.744979\n",
       "5       random_forest_r  0.958936  0.741947\n",
       "0     linear_regression  0.656002  0.695278\n",
       "1                 lasso  0.655084  0.690669\n",
       "4       decision_tree_g  0.676867  0.664391\n",
       "7  adaboost_regressor_g  0.576523  0.592496\n",
       "3       decision_tree_r  0.497886  0.528981"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model names\n",
    "model_names = [\"linear_regression\", \n",
    "               \"lasso\", \n",
    "               \"xgb_regressor\", \n",
    "               \"decision_tree_r\", \n",
    "               \"decision_tree_g\",\n",
    "               \"random_forest_r\",\n",
    "               \"random_forest_g\",\n",
    "               \"adaboost_regressor_g\"]\n",
    "\n",
    "# Set R2 scores for test set\n",
    "test_r2_scores = [r2_score(Y_test, Y_test_pred), \n",
    "                 gridsearch_lasso.score(X_test, Y_test), \n",
    "                 xgb_gridsearch.score(X_test, Y_test),\n",
    "                 tree_regressor.score(X_test, Y_test),\n",
    "                 dt_opt.score(X_test, Y_test),\n",
    "                 rf.score(X_test, Y_test),\n",
    "                 rfg_gridsearch.score(X_test, Y_test),\n",
    "                 ada_gridsearch.score(X_test, Y_test)\n",
    "]\n",
    "\n",
    "# Set R2 scores for training set\n",
    "train_r2_scores = [r2_score(Y_train, Y_train_pred), \n",
    "                   gridsearch_lasso.score(X_train, Y_train), \n",
    "                   xgb_gridsearch.score(X_train, Y_train),\n",
    "                   tree_regressor.score(X_train, Y_train),\n",
    "                   dt_opt.score(X_train, Y_train),\n",
    "                   rf.score(X_train, Y_train),\n",
    "                   rfg_gridsearch.score(X_train, Y_train),\n",
    "                   ada_gridsearch.score(X_train, Y_train)\n",
    "]\n",
    "\n",
    "# Create the DataFrame\n",
    "df_scores = pd.DataFrame({\"Model\": model_names,\n",
    "                          \"Train R2\": train_r2_scores,\n",
    "                          \"Test R2\": test_r2_scores})\n",
    "\n",
    "df_sorted = df_scores.sort_values(by='Test R2', ascending=False)\n",
    "\n",
    "df_sorted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is XGBBOOST Regressor gridsearch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on training set :  0.8285923861125634\n",
      "R2 on test set :  0.7429685498975729\n"
     ]
    }
   ],
   "source": [
    "# Voting\n",
    "voting = VotingRegressor(estimators=[(\"linear_regression\", linreg), (\"random_forest_grid\", rfg), ('xgboost_r', xgb), (\"decision_tree\", dt_opt), (\"adaboost\", ada_gridsearch)])\n",
    "voting.fit(X_train, Y_train)\n",
    "print(\"R2 on training set : \", voting.score(X_train, Y_train))\n",
    "print(\"R2 on test set : \", voting.score(X_test, Y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\33760\\\\Desktop\\\\FULLSTACK\\\\FULLSTACK\\\\Projet\\\\Get around\\\\api\\\\ml_best_model.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Path\n",
    "path = r'C:\\Users\\33760\\Desktop\\FULLSTACK\\FULLSTACK\\Projet\\Get around\\api\\ml_best_model.pkl'\n",
    "\n",
    "# Download model\n",
    "joblib.dump(voting, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
